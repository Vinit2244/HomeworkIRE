data:
  # There is wikipedia dataset as well but it can be used directly from datasets library
  news:
    path: /Users/vinitmehta/Desktop/IIITH/Sem7/IRE/Assignments/HomeworkIRE/data/news
    unzip: true # Download the data and unzip it
  wikipedia:
    path: /Users/vinitmehta/Desktop/IIITH/Sem7/IRE/Assignments/HomeworkIRE/data/wikipedia

preprocessing:
  stopwords:
    languages: [auto, english] # List of languages for stopword removal. Empty list means no stopword removal. "auto" means it will automatically look for language tag in the data file itself
  stemming:
    algorithm: porter # porter, lancaster, snowball, null (no stemming)
  lemmatization:
    algorithm: wordnet # wordnet, null (no lemmatization)
  lowercase: true
  remove_punctuation: true
  remove_numbers: true
  remove_special_characters: true

elasticsearch:
  host: localhost
  port: 9200
  scheme: http     # https for secure connection, http for local connection
  chunk_size: 500  # Number of documents to index in one bulk operation

index:
  core: ESIndex    # Options: "ESIndex" (Elasticsearch), "CustomIndex" (Custom Index)
  dataset: Wikipedia    # Options: "News" (News Dataset), "Wikipedia" (Wikipedia Dataset)

# NOTE: !!!!!! PLEASE ALWAYS KEEP THE UNIQUE ID AS THE FIRST ATTRIBUTE IN THE LIST !!!!!!
  attributes: [uuid, text] # Attributes to be indexed from the dataset (Make sure to keep the unique id as first attribute)
  
  info: TFIDF    # Kind of information indexed: BOOLEAN, WORDCOUNT or TFIDF
  dstore: CUSTOM   # Datastore choice: CUSTOM, MONGODB or REDIS
  compr: NONE      # Compression choice: NONE, CODE or CLIB
  optim: NONE      # Optimisation choice: NONE, SKIPPING, THRESHOLDING or EARLYSTOPPING
  qproc: TERM      # Query Processing choice: TERM or DOC

search_fields: [text]     # The field in the indexed documents to be searched (all fields to be searched must also be present in the 'attributes' list under 'index' section)
max_results: 50           # The number of top document IDs to retrieve for each query
max_num_documents: 5000   # Maximum number of documents to be processed from each dataset. Set to null to process all documents
top_k_words_threshold: 50 # Top K words to be plotted in frequency distribution plots
output_folder_path: /Users/vinitmehta/Desktop/IIITH/Sem7/IRE/Assignments/HomeworkIRE/output
storage_folder_path: /Users/vinitmehta/Desktop/IIITH/Sem7/IRE/Assignments/HomeworkIRE/storage
