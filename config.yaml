data:
  # There is wikipedia dataset as well but it can be used directly from datasets library
  news:
    path: /Users/vinitmehta/Desktop/IIITH/Sem7/IRE/Assignments/HomeworkIRE/data/news
    unzip: true # Download the data and unzip it
  wikipedia:
    path: /Users/vinitmehta/Desktop/IIITH/Sem7/IRE/Assignments/HomeworkIRE/data/wikipedia

preprocessing:
  stopwords:
    languages: [auto, english] # List of languages for stopword removal. Empty list means no stopword removal. "auto" means it will automatically look for language tag in the data file itself
  stemming:
    algorithm: porter # porter, lancaster, snowball, null (no stemming)
  lemmatization:
    algorithm: wordnet # wordnet, null (no lemmatization)
  lowercase: true
  remove_punctuation: true
  remove_numbers: true
  remove_special_characters: true

elasticsearch:
  host: localhost
  port: 9200
  index_name: ESIndex-v1.0

max_num_documents: 5000 # Maximum number of documents to be processed from each dataset. Set to null to process all documents
top_k_words_threshold: 50 # Top K words to be plotted in frequency distribution plots
output_folder_path: /Users/vinitmehta/Desktop/IIITH/Sem7/IRE/Assignments/HomeworkIRE/output
